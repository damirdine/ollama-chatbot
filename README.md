# ğŸ§  Ollama Chatbot (FastAPI)

Ce projet est une API de chatbot local basÃ© sur [Ollama](https://ollama.com/) et [FastAPI](https://fastapi.tiangolo.com/), avec rÃ©ponses en streaming type ChatGPT. Il utilise une architecture modulaire testable (DDD-style) et enregistre les conversations uniquement en mÃ©moire.

## ğŸš€ FonctionnalitÃ©s

* ğŸ“¡ API REST `/chat` avec streaming `text/event-stream`
* ğŸ’¬ Conversations par ID unique avec historique
* ğŸ§± Architecture modulaire (domain / services / api)
* ğŸ§ª Tests unitaires avec `pytest`
* âš¡ Compatible avec [Ollama](https://ollama.com) local (ex: `llama3`)

## âš™ï¸ PrÃ©requis

Avant de commencer, assure-toi d'avoir les Ã©lÃ©ments suivants installÃ©s sur ton systÃ¨me :

* Python 3.8 ou version supÃ©rieure
* [Poetry](https://python-poetry.org/) pour la gestion des dÃ©pendances
* [Ollama](https://ollama.com/) installÃ© et configurÃ© avec un modÃ¨le compatible, comme `llama3` ou autre.

## âš™ï¸ Installation

```bash
git clone https://github.com/ton-utilisateur/ollama-chatbot.git
cd ollama-chatbot
poetry install
```

> Assure-toi quâ€™Ollama est installÃ© et quâ€™un modÃ¨le (ex: `llama3`) est chargÃ©.

## ğŸš€ Lancement

```bash
poetry run dev
# ou
poetry run uvicorn app.main:app --reload
```

* Docs API : [http://localhost:8000/docs](http://localhost:8000/docs)
* ReDoc : [http://localhost:8000/redoc](http://localhost:8000/redoc)

## ğŸ”Œ API

### `POST /chat`

```json
{
  "message": "Bonjour !",
  "conversation_id": "facultatif"
}
```

* `text/event-stream` SSE
* Header `X-Conversation-ID` en rÃ©ponse

## ğŸ§ª Tests

```bash
poetry run pytest
```

## ğŸ“ Structure

```
app/
â”œâ”€â”€ api/         # Routes
â”œâ”€â”€ domain/      # ModÃ¨les
â”œâ”€â”€ schemas/     # Pydantic
â”œâ”€â”€ services/    # Logique mÃ©tier
â”œâ”€â”€ main.py      # EntrÃ©e FastAPI
```

---

Â© Damirdine ALI SOILIHI â€” MIT
